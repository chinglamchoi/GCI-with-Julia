{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare SentimentAnalysis models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dependencies & Pre-processing\n",
    "To derive files test_X, test_Y, I split the labels and review for each line in the original Amazon Reviews dataset. I then replace \"\\__label\\__\" with null, and only keep the numerical sentiment label. I write the label and review data into 2 separate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: Package TextAnalysis not found in current path:\n- Run `import Pkg; Pkg.add(\"TextAnalysis\")` to install the TextAnalysis package.\n",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Package TextAnalysis not found in current path:\n- Run `import Pkg; Pkg.add(\"TextAnalysis\")` to install the TextAnalysis package.\n",
      "",
      "Stacktrace:",
      " [1] require(::Module, ::Symbol) at .\\loading.jl:887",
      " [2] top-level scope at In[13]:1"
     ]
    }
   ],
   "source": [
    "using TextAnalysis\n",
    "\n",
    "testset = Array{String, 1}(undef, 400000)\n",
    "file1 = open(\"test_X.txt\")\n",
    "\n",
    "global cnt = 1\n",
    "for i in readlines(file1)\n",
    "    if length(i) > 500\n",
    "        try\n",
    "            testset[cnt] = i[1:500]\n",
    "        catch e\n",
    "            # char at index 500 is of iso-8859-1 not Unicode!\n",
    "            testset[cnt] = i[1:499]\n",
    "        end\n",
    "    else\n",
    "        testset[cnt] = i\n",
    "    end\n",
    "    global cnt += 1\n",
    "end\n",
    "close(file1)\n",
    "\n",
    "#simultaneous iter gives bug for testset\n",
    "\n",
    "testlabels = Array{Int8, 1}(undef, 400000)\n",
    "file2 = open(\"test_Y.txt\")\n",
    "global cnt = 1\n",
    "for j in readlines(file2)\n",
    "    testlabels[cnt] = parse(Int8, j)\n",
    "    global cnt += 1\n",
    "end\n",
    "close(file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load pretrained TextAnalysis model & test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assess the model based on accuracy, precision, recall, and F1 score.\n",
    "After conducting pre-processing of truncating at 500 chars, stripping stopwords, stripping non-utf8 (iso-8859-1) chars, here are my results:\n",
    "- Accuracy = $\\frac{100*total correct}{total}=49.64325$\n",
    "<br>\n",
    "<br>\n",
    "- Precision = $\\frac{true positive}{true positive + false positive}=0.497469903015904$\n",
    "<br>\n",
    "<br>\n",
    "- Recall = $\\frac{true positive}{true positive + false negative}=0.701445$\n",
    "<br>\n",
    "<br>\n",
    "- F1 Score = $\\frac{2*precision*recall}{precision+recall}=0.5821059947510917$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentAnalyzer()\n",
    "global total_correct, total_valid = 0, 0\n",
    "global cnt = 1\n",
    "global boundserror = []\n",
    "global tp, fp, fn = 0,0,0 #positive sentiment = positive\n",
    "\n",
    "for i in 1:400000\n",
    "    input = Document(testset[i])\n",
    "    prepare!(input, strip_stopwords)\n",
    "    prepare!(input, strip_corrupt_utf8)\n",
    "    prepare!(input, stem_words)\n",
    "    try\n",
    "        pred = Int8.(round(model(input))) + 1\n",
    "        if pred == 2\n",
    "            (testlabels[i] == 2) ? (global total_correct += 1; global tp += 1) : (global fp += 1) \n",
    "        else\n",
    "            (testlabels[i] == 1) ? (global total_correct += 1) : (global fn += 1) \n",
    "        end\n",
    "        global total_valid += 1\n",
    "    catch e\n",
    "        push!(boundserror, i)\n",
    "    end\n",
    "    if i % 1000 == 0 \n",
    "        println(\"[\", cnt, \"]: \", total_correct/total_valid*100)\n",
    "        global cnt += 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of TextAnalysis' pretrained model is 49.64325\n",
      "Precision: 0.497469903015904\n",
      "Recall: 0.701445\n",
      "F1 Score: 0.5821059947510917\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "println(\"The accuracy of TextAnalysis' pretrained model is \", total_correct/total_valid*100)\n",
    "precision =  tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "println(\"Precision: \", precision)\n",
    "println(\"Recall: \", recall)\n",
    "println(\"F1 Score: \", 2*precision*recall/(precision+recall))\n",
    "println(length(boundserror))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
